# 多重输出的收缩和选择

## 1 概述

* 多重输出线性模型的最小二乘估计可以简单地看成是关于每个输出的最小二乘估计

* 在多重输出情况下应用选择和收缩的方法

  * 可以对每个输出变量单独地应用单变量的技巧
  * 或对全部的输出变量同时进行

* 例如对于岭回归的每一列，应用
  $$
  \hat\beta^{ridge}=(X^TX+\lambda I)^{-1}X^Ty
  $$
  
  * 第一种策略允许对不同的输出应用不同程度的正则化，但是需要估计 $k$ 个独立的正则化参数$\lambda_1, \lambda_2,\dots,\lambda_k$
  * 第二种策略可以在估计单独的正则化参数 $\lambda$ 时应用全部的 $k$ 个输出

* 更复杂的收缩和选择的策略可以利用多重输出情形中不同响应变量间的相关性，例如在输出变量有
  $$
  Y_k=f(X)+\epsilon_k\\
  Y_l=f(X)+\epsilon_l
  $$
  这种情况下，两者享有相同的结构$f(X)$, 因此应该合并 $Y_k$ 和 $Y_l$ 来估计共同的$f$

## 2 典型相关分析

* 概念：**典型相关分析 (canonical correlation analysis, CCA)** 的核心是合并响应变量，是一种为多元输出情形提出的数据降维的技巧。CCA是在进行降维，将高维数据降到1维，然后再用相关系数进行相关性的分析

* 算法过程：

  * 重复一下过程$M=Min(k,p)$次，即$m=1,2,\dots,M$

    * 对$X$进行降维，找到与之前预测变不相关的线性组合$Xv_m$
    * 对$Y$进行降维，找到与之前不相关的线性组合$Yu_m$
    * 最大化系数

    $$
    Corr(Xv_m,Yu_m)=\frac{Cov(Xv_m,Yu_m)}{\sqrt{Var(Xv_m)Var(Yu_m)}}
    $$

  * 第一典则响应变量就是被$X$最优预测的线性组合导出的响应变量

  * 最后典则响应变量就是被$X$估计最差的

* 具体求解方法

  * CCA 的解通过对样本交叉协方差矩阵$\frac{Y^TX}{N}$进行SVD得到
  * 具体请参考[习题 Ex 3.20](./A 习题)

* $u_m$被称为左典则向量，$v_m$称为右典则向量

## 3 降秩回归

* 概念：**降秩回归 (reduced-rank regression)** 采用显式地合并信息的回归模型，并且可以形式化

* 形式化公式（给定误差协;方差$Cov(\epsilon)=\Sigma$）
  $$
  \hat B^{rr}(m)={\arg\max}_{rank(B)=m}\sum_{i=1}^N(y_i-B^Tx_i)^T\Sigma^{-1}(y_i-B^Tx_i)
  \\ = {\arg\max}_{rank(B)=m}tr((Y-XB)\Sigma^{-1}(Y-XB)^T)
  $$
  

* 求解：

  * 将 $\Sigma$ 用估计值 $Y^TY/N$ 替换, 可以得出其解为
    $$
    \hat B^{rr}(m)=\hat BU_mU_m^-
    $$

    * 其中$U_m$是$U$前$m$列构成的$K\times m$的子矩阵，$U$是$K\times M$的左典则向量$u_1,u_2,\dots,u_M$构成的矩阵，$U_m^-$是其广义逆

  * 求解过程参考[习题 Ex 3.21](.\A 习题)

  