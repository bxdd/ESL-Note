# 相关系数与(协)方差

## 1 样本方差

* 公式
  $$
  S^2=\frac{1}{N-1}\sum_{i=1}^N(x_i-\bar x)^2
  $$

* 分母为什么是$N-1$而不是$N​$

  * 对于正态分布的情况，可以从自由度角度理解，可以通过正交变换为$N-1​$个独立服从正态分布的变量，而正交变换并不会改变其分布。正交变换之后，$\frac{(N-1)S^2}{\sigma^2}​$服从自由度为$N-1​$的卡方分布，因此$S^2​$是$\sigma^2​$的无偏分布

  * 对于其他情况，也需要证明其是无偏分布

    * 首先看$\tilde S^2=\frac{1}{N}\sum_{i=1}^N(x_i-\bar x)^2$期望

      $$
      (1)\\E(\tilde S^2)=E(\frac{1}{N}\sum_{i=1}^N(x_i-\bar x)^2)
      \\ = E(\frac{1}{N}\sum_{i=1}^N(x_i-\mu)^2-2(\bar x-\mu)(x_i-\mu)+(\bar x-\mu)^2)
      \\ = E(\frac{1}{N}\sum_{i=1}^N(x_i-\mu)^2-\frac{2}{N}(\bar x-\mu)\sum_{i=1}^N(x_i-\mu)+(\bar x-\mu)^2)
      \\ = E(\frac{1}{N}\sum_{i=1}^N(x_i-\mu)^2-2(\bar x-\mu)(\bar x-\mu)+(\bar x-\mu)^2)
      \\ = E(\frac{1}{N}\sum_{i=1}^N(x_i-\mu)^2-(\bar x-\mu)^2)
      \\ = \sigma^2 -E((\bar x-\mu)^2)
      \\ = \sigma^2 -E((\bar x-E(\bar x))^2)
      \\ = \sigma^2 -Var(\bar x)
      \\ = \sigma^2 -\frac{\sigma^2}{N}
      \\ = \frac{N-1}{N}\sigma^2
      \\ (2)
      \\ E(\tilde S^2)=E(\frac{1}{N}\sum_{i=1}^N(x_i-\bar x)^2)
      
      \\ =E(\frac{1}{N}\sum_{i=1}^N( x_i^2-2x_i\bar x+\bar x^2))
      \\ =E(\frac{1}{N}(\sum_{i=1}^N x_i^2-2\sum_{i=1}^Nx_i\bar x+\sum_{i=1}^N\bar x^2)))
      \\ =E(\frac{1}{N}(\sum_{i=1}^N x_i^2-2N\bar x^2+N\bar x^2)))
      \\ =E(\frac{\sum_{i=1}^N x_i^2}{N}-\bar x^2)
      \\ = \frac{NE(x^2)}{N}-E(\frac{\sum_{i=1} x_i}{N}\frac{\sum_{i=1} x_i}{N})
      \\ = E(x^2)-E(\sum_{i=1}^N \frac{x_i^2}{N^2})+E(\frac{\sum_{i=1}^N\sum_{j\neq i}^Nx_ix_j}{N^2})
      \\ = E(x^2)-\sum_{i=1}^N \frac{E(x_i^2)}{N^2}+\sum_{i=1}^N\sum_{j\neq i}^N\frac{E(x_ix_j)}{N^2}
      \\ = E(x^2)-\sum_{i=1}^N \frac{E(x^2)}{N^2}+\frac{N(N-1)}{N^2}E(x)^2 \ \because 观测独立,x_i 和 x_j 相互独立
      \\ = \frac{N-1}{N}(E(x^2)-E(x)^2)
      \\ = \frac{N-1}{N} \sigma^2
      $$

    * 因此
      $$
      E(S^2)=\frac{N}{N-1}E(\tilde S^2)=\sigma^2
      $$
      


## 2 样本协方差

* 公式
  $$
  S_{xy}=\frac{1}{N-1}\sum_{i=1}^N(x_i-\bar x)(y_i-\bar y)\\
  $$

* 分母为什么是$N-1$而不是$N$

  * 首先看$\tilde S_{xy}=\frac{1}{N}\sum_{i=1}^N(x_i-\bar x)(y_i-\bar y)$期望
    $$
    E(\tilde S_{xy})=\frac{1}{N}E(\sum_{i=1}^N(x_i-\bar x)(y_i-\bar y))
    
    \\ =E(\frac{1}{N}\sum_{i=1}^N( x_iy_i-x_i\bar y-y_i\bar x+\bar x\bar y))
    \\ =E(\frac{1}{N}(\sum_{i=1}^N x_iy_i-\sum_{i=1}^Nx_i\bar y-\sum_{i=1}^Ny_i\bar x+\sum_{i=1}^N\bar x\bar y)))
    \\ =E(\frac{1}{N}(\sum_{i=1}^N x_iy_i-2N\bar x\bar y+N\bar x\bar y)))
    \\ =E(\frac{\sum_{i=1}^N x_iy_i}{N}-\bar x\bar y) 
    \\ = \frac{NE(xy)}{N}-E(\frac{\sum_{i=1} x_i}{N}\frac{\sum_{i=1} y_i}{N})
    \\ = E(xy)-E(\sum_{i=1}^N \frac{x_iy_i}{N^2})+E(\frac{\sum_{i=1}^N\sum_{j\neq i}^Nx_iy_j}{N^2})
    \\ = E(xy)-\sum_{i=1}^N\frac{E(x_iy_i)}{N^2}+\sum_{i=1}^N\sum_{j\neq i}^N\frac{E(x_ix_j)}{N^2}
    \\ = E(x^2)-\sum_{i=1}^N \frac{E(xy)}{N^2}+\frac{N(N-1)}{N^2}E(x)E(y) \ \because 观测独立，所以x_i和y_j独立
    \\ = \frac{N-1}{N}(E(xy)-E(x)E(y))
    \\ = \frac{N-1}{N} Cov(x,y)
    $$

  * 因此
    $$
    E(S_{xy})=\frac{N}{N-1}E(\tilde S_{xy})=Cov(x,y)
    $$
    

## 3 皮尔逊积矩相关系数

* 介绍：**皮尔逊积矩相关系数**（英语：Pearson product-moment correlation coefficient）用于度量两个变量X和Y之间的相关程度

* 总体相关系数：

  * **总体**相关系数，常用希腊小写字母 *ρ* (rho) 作为代表符号

  * 公式：
    $$
    \rho_{X,Y}=\frac{Cov(X,Y)}{\sigma_X\sigma_Y}=\frac{E((X-E(X)(Y-E(Y))))}{\sqrt{E((X-E(X))^2)}\sqrt{E((Y-E(Y))^2)}}
    $$

  * 其他形式
    $$
    \rho_{X,Y}=\frac{E((X-E(X)(Y-E(Y))))}{\sqrt{E((X-E(X))^2)}\sqrt{E((Y-E(Y))^2)}}
    \\ = \frac{E(XY)-E(X)E(Y)}{\sqrt{(E(X^2)-E(X)^2})\sqrt{(E(Y^2)-E(Y)^2)}}
    $$
    

* 样本相关系数

  * 估算样本的协方差和标准差，可得到**样本相关系数**(样本皮尔逊系数)，常用英文小写字母 r 表示

  * 公式：
    $$
    r=\frac{\frac{1}{N-1}\sum_{i=1}^N (X_i-\bar X)(Y_i-\bar Y)}{\sqrt{\frac{1}{N-1}\sum_{i=1}^N(X_i-\bar X)^2\frac{1}{N-1}\sum_{i=1}^N(Y_i-\bar Y)^2}}
    \\ = \frac{\sum_{i=1}^N (X_i-\bar X)(Y_i-\bar Y)}{\sqrt{\sum_{i=1}^N(X_i-\bar X)^2\sum_{i=1}^N(Y_i-\bar Y)^2}}
    $$

  * r可由$(X_i,Y_i)$样本点的标准分数均值估算
    $$
    r = \frac{1}{N-1}\sum_{i=1}^N\frac{X_i-\bar X}{S_X}\frac{Y_i-\bar Y}{S_Y}
    $$

  * 其他形式
    $$
    r=\frac{\sum_{i=1}^N (X_i-\bar X)(Y_i-\bar Y)}{\sqrt{\sum_{i=1}^N(X_i-\bar X)^2\sum_{i=1}^N(Y_i-\bar Y)^2}}
    \\ =E(\frac{\sum_{i=1}^N X_iY_i-N\bar X\bar Y}{\sqrt{(\sum_{i=1}^N X_i^2-N\bar X^2)(\sum_{i=1}^N Y_i^2-N\bar Y^2))}}
    \\ =E(\frac{N\sum_{i=1}^N X_iY_i-\sum_{i=1}^N X_i\sum_{i=1}^N Y_i}{\sqrt{(N\sum_{i=1}^N X_i^2-(\sum_{i=1}^N X_i)^2)(N\sum_{i=1}^N Y_i^2-(\sum_{i=1}^N Y_i)^2))}}
    $$



## 4 对预测变量的估计

* 对于$X​$的样本协方差矩阵，
  $$
  \Sigma_{\mathbf{x}} = (X-\mathbf{\bar x})^T(X-\mathbf{\bar x})/(N-1)
  $$

* 这是因为
  $$
  {\Sigma_{\mathbf{x}}}_{a,b} = \frac{\sum_{i=1}^N (X_{ia}-\mathbf{\bar x}_a)(X_{ib}-\mathbf{\bar x}_b)}{N-1}
  \\ = \frac{\sum_{i=1}^N (X_{ia}-\frac{\sum_{i=1}^N X_{ia}}{N})(X_{ib}-\frac{\sum_{i=1}^N X_{ib}}{N})}{N-1}
  $$

* 也正符合协方差的公式
  $$
  {\Sigma_{\mathbf{x}}}_{a,b} =S_{X_{a}X_{b}} =\frac{\sum_{i=1}^N (X_{ia}-\mathbf{\bar x}_a)(X_{ib}-\mathbf{\bar x}_b)}{N-1}
  $$
  

## 5 对响应变量的估计

### 5.1 响应变量为一维

* 可以和普通变量一样估计，但是存在更自然的方法

* 无偏估计方差方法为
  $$
  \hat \sigma^2 = \frac{1}{N-p}(y-X\hat \beta)^T(y-X\hat \beta)
  $$

* 具体证明请参考 ESL-Note 的3.2节证明



### 5.2 多重输出的响应变量

* 可以和普通变量一样估计，但是存在更自然的方法

* 但是存在更自然的估计方式，假设有高斯-马尔可夫假设（Gauss-Markov）：对于多重输出响应变量，$\mathbf{y}_i$（行之间）不相关，且$\mathbf{y}_i$ 有固定的协方差矩阵$\Sigma$, 且 $X$ 是固定的（非随机）

* 估计方法：

  * 对于多元的线性回归，有

  $$
  \hat Y= X\hat B
  $$

  * 则无偏估计方法为
    $$
    \Sigma = (Y-X\hat B)^T(Y-X\hat B)/(N-pK)
    $$

* 证明（TODO 这里还没搞懂为啥）：

  * 进行化简得到
    $$
    (Y-X\hat B)^T(Y-X\hat B)
    \\ = ([y_1,y_2,\cdots,y_K]-X[\hat\beta_1\hat\beta_2,\dots,\hat\beta_K])^T([y_1,y_2,\cdots,y_K]-X[\hat\beta_1\hat\beta_2,\dots,\hat\beta_K])
    \\ = 
    \left\{
    \begin{matrix}
    (y_1-X\hat\beta_1)^T \\
    (y_2-X\hat\beta_2)^T \\
    \vdots\\
    (y_K-X\hat\beta_K)^T \\
    \end{matrix}
    \right\}
    \left\{
    \begin{matrix}
    y_1-X\hat\beta_1 &
    y_2-X\hat\beta_2 &
    \cdots &
    y_K-X\hat\beta_K
    \end{matrix}
    \right\}
    $$

  * 因此
    $$
    \Sigma_{ij}=(y_i-X\hat\beta_i)^T(y_j-X\hat\beta_j) / (N-pK)
    $$

  * 这里和前面单变量冲突啊，不是很懂为什么分母是$N-pK$, 但是**习题 Ex 3.22**是这样的