# 指示矩阵的线性回归

## 1 指示变量相应矩阵

* 有$K$个类别，则会有$K$个指示变量$Y=(Y_1,Y_2,\cdots, Y_K)$, 可以得到指示变量相应矩阵$\mathbf{Y}$, 由01组成

* 可以对$Y$的每一列用线性回归做拟合，得到
  $$
  \hat Y = X(X^TX)^{-1}X^TY
  $$

* 其中
  $$
  \hat B = (X^TX)^{-1}X^TY
  $$

  

## 2 分类准则

* 因此对于输入$x$, 可以如此分类
  * 步骤
    * 计算$\hat f(x)^T =(1,x^T)\hat B$， 得到$K$维向量
    * 采用值最大组$\hat G(x) = \arg\max_{k\in G} \hat f_k(x)​$
  * 该方法可以把回归看作条件期望$E(Y_k|X=x)=Pr(G=k|X=x)$的估计
    * 可以证明，$\sum_{k\in G}\hat f_k(x) = 1$ (TODO)
    * 但是由于线性回归的**刚性本质 (ridge nature)** ，特别是如果我们在训练数据之外做预测时，困难出现$\hat f_k(x)$是负数或者大于1

* 更合理的方法是采用目标值去理解

  * 对于$Y$的第$i$行，采用编码方法，如果是第$k$类则为$e_k^T$

  * 通过最小二乘法来拟合线性模型, 这个准则是目标值到拟合向量的欧几里得距离的平方和
    $$
    \min_B tr((Y-XB)^T(Y-XB))
    $$

  * 对于新的观测值，只需要使得它的拟合向量到最近的目标值$e_k$作为其类别$G=k$
    $$
    \hat G(x)=\arg\min_k\{(\hat f(x) - e_k)^T(\hat f(x) - e_k)\}
    $$

  * 平方和准则恰巧是**多重响应变量线性回归** 准则

  * 同时，该目标分类准则，和上面$\hat G(x) = \arg\max_{k\in G} \hat f_k(x)$是一致的

## 3 掩盖问题

* 描述：类别的数目$K\ge 3$ 时候回归方法有个很严重的问题，特别当 $K$ 很大时, 由于回归模型的刚性性质，某个类别可以被其他的类别掩盖掉 (masked)
  * 右图显示了通过线性判别分析找到的边界；左图显示了通过对指示响应变量的线性回归找到的边界，中间的类别完全被掩盖掉了![1620062734849](assets/1620062734849.png)

