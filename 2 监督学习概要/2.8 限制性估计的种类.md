# 2.8 限制估计的种类

## 1 粗糙度惩罚和贝叶斯方法

* 由显式的惩罚 $RSS(f)$ 以及粗糙度惩罚控制的函数类别
  $$
  PRSS(f;\lambda)=RSS(f)+\lambda J(f)
  $$
  

* 举例：三次光滑样条
  $$
  PRSS(f;\lambda)=\sum_{i=1}^N (y_i-f(x_i))^2
  $$
  这里的粗糙惩罚控制了$f$ 的二阶微分较大的值，而且惩罚的程度由 $\lambda \ge 0$ 来决定。$\lambda=0$ 表示没有惩罚，则可以使用任意插值函数，$\lambda=\infin$仅仅允许关于 $x$ 的线性函数。

* 举例：可加性函数
  $$
  f(X)=\sum_{j=1}^pf_j(X_j), J(f)=\sum_{j=1}^p J(f_j)
  $$
  可加性惩罚与可加性函数 联合使用去构造可加的光滑坐标函数的模型

* 举例：投影映射回归 (Projection Pursuit Regression)

  

* 惩罚函数，或者说 **正则 (regularization)** 方法，表达了我们的 **先验信仰 (prior belief)**

