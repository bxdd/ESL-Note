# 2.5 高维问题的局部方法

## 1 高维度的一些问题

* 对于输入在 p 维单位超立方体均匀分布的最近邻过程
  * 假设邻域的体积对应单位体积的比例为r
  * 则边长的期望值$e_p(r)=r^{\frac{1}{p}}​$， $e_{10}(0.01)=0.63​$，$e_{10}(0.1)=0.80​$。也就是说，对于每个变量输入为[0,1], 选取1%或者10%的数据去形成局部均值。
  * 这意味着必须在每个输入变量上覆盖到 63% 或者 80%．这样的邻域不再是局部的．显著地降低 r 并没有作用，因为我们选取去平均的观测值越少，拟合的方差也会越大．

* 最近邻距离的中位数

  * 问题：考虑在 p 维以原点为中心的单位球中均匀分布的 N 个数据点．假设我们考虑原点处的最近邻估计．距离原点最近的数据点距离的中位数$d(p,N)$：

  * 求解：

    * 数据点与原点的距离看成随机变量X，因为数据点均匀分布，则 X 的分布函数正比于$x^p$
      $$
      F(X<x)=x^p
      $$

    * 则次序统计量$X_{(1)}$的分布满足
      $$
      F(X_{(1)} < x) = 1-F(X_{(1)}>=x)
      \\=1-(1-F(X<x))^N
      \\ =1-(1-x^p)^N=\frac{1}{2}
      $$

    * 解得
      $$
      median(X_{(1)})=(1-\frac{1}{2^{1/n}})^{1/p}
      $$

  * N=500，p=10的时候，$d(p, N)\approx 0.52$,即大部分的数据点离样本空间的边界比其他任何的数据点更近．

* 取样密度

  * 取样密度是跟 $N^{1/p}$成比例, 也就是说要达到同样取样密度，p维空间样本数目是单维的p次方倍
  * 因此在高维空间中所有可行的训练样本在输入空间中很稀少

## 2 方差偏差分析

* 方差-偏差分解

  * 泛化误差可分解为偏差、方差与噪声之和

  * 有噪声：对于数据集$D$求期望

    * 假设：

      * $\bar f(x) = E_D(f(x;D))$
      * $y$为$x​$的真实标记
      * $y_D​$是$x​$在数据集中的标记
      * $Var_D(x)=E_D(f(x;D)-\bar f(x))$
      * $Bias^2(x)=(\bar f(x)-y)^2$
      * 假定噪声的期望$E_D(y-y_D)​$为0

    * 根据定义
      $$
      E(f;D)=E_D((f(x;D)-y_D)^2)\\
      \\=E_D((f(x;D) - \bar f(x) + \bar f(x) -y_D)^2)
      \\=E_D((f(x;D)-\bar f(x))^2)+E_D((\bar f(x) - y_D)^2)+2E_D((f(x;D) - \bar f(x))(\bar f(x) - y_D))
      $$

    * 假设噪声$y_D-y$和$f(x;D)$ 线性无关（TODO: 质疑），其中最后一项为0
      $$
      E_D((f(x;D) - \bar f(x))(\bar f(x) - y_D))\\
      =E_D(f(x;D)(\bar f(x)-y_D))-E(\bar f(x)(\bar f(x)-y_D))\\
      =\bar f(x)^2-E_D(f(x;D)y_D)-\bar f(x)^2+E(\bar f(x)y_D)
      \\=\bar f(x)E_D(y_D)-E_D(f(x;D)(y_D-y))+\bar f(x)y
      \\ = \bar f(x)E_D(y_D)-\bar f(x)(y_D-y))+\bar f(x)y=0
      $$

    * 从而继续有
      $$
      E(f;D)=E_D((f(x;D)-\bar f(x))^2)+E_D((\bar f(x) - y_D)^2)
      \\=E_D((f(x;D)-\bar f(x))^2)+E_D((\bar f(x) - y + y - y_D)^2)
      \\=E_D((f(x;D)-\bar f(x))^2)+E_D((\bar f(x) - y)^2)+E((y - y_D)^2)+2E((\bar f(x) - y)(y - y_D))
      $$

    * 其中，最后一项仍为0，PS: $\bar f(x)$、$y$均为常数项
      $$
      E((\bar f(x) - y)(y - y_D))=E(\bar f(x) - y))E(y-y_D)=0
      $$

    * 则最后有
      $$
      E(f;D)=E_D((f(x;D)-\bar f(x))^2)+(\bar f(x) - y)^2+E((y - y_D)^2)
      \\=Var_D(x)+Bias^2(x)+\epsilon^2
      $$

  * 无噪声

    * 根据定义
      $$
      E(f;D)=E_D((f(x;D)-y)^2)\\
      \\=E_D((f(x;D) - \bar f(x) + \bar f(x) -y)^2)
      \\=E_D((f(x;D)-\bar f(x))^2)+E_D((\bar f(x) - y)^2)+2E_D((f(x;D) - \bar f(x))(\bar f(x) - y))
      \\ = E_D((f(x;D)-\bar f(x))^2)+E_D((\bar f(x) - y)^2)+2(\bar f(x)-\bar f(x))(\bar f(x)-y)
      \\=E_D((f(x;D)-\bar f(x))^2)+(\bar f(x) - y)^2
      \\=Var_D(x)+Bias^2(x)
      $$
      

* 分析：有这么一个数据集：假设从$[-1,1]^p$中均匀产生1000个样本$\{x_i\}$， 假设没有测量错误，对于每个$X$label $Y$，关系为
  $$
  Y=h(X)=\exp(-8\|X\|^2)
  $$

  * 采用最近邻估计$x_0=0$处的值，其中$f(x;D)$是采用最近邻模型下，数据集为D情况下预测的x的label
    $$
    E(f;D)=E((f(x_0;D)-y_0)^2)
    \\=E_D((f(x_0;D)-\bar f(x_0))^2)+(\bar f(x_0)-y_0)^2
    \\ = Var_D(x_0)+Bias^2(x_0)
    $$

  * 根据函数图像，其偏差应该会<0, 而不是无偏估计

    ![1608574654318](assets/1608574654318.png)

  * 低维度情况下，最近邻非常接近 0，于是偏差和方差都会非常小．
  * 当维数增大，最近邻有从目标点远离的趋势
    * ![1608574841418](assets/1608574841418.png)
    * 偏差增长到1左右，因为p=10 时，超过 99% 的样本的最近邻距离原点大于 0.5，此时函数值为0
    * 方差则和函数斜率相关，先增长后下降

* 方差占主导地位的情况：

  * 在低维度，方差可能更占据主导地位