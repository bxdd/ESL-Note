# 加权最小二乘法

## 1 普通最小二乘法

* 普通最小二乘法是应用最广泛的一种最小二乘法，它的目标是求得一个使得全局残差平方和最小的参数。假设有$N$个样本$x=(x_1,x_2,...,x_N)$，普通最小二乘法要求残差$\epsilon=(\epsilon_1, \epsilon_2, \dots,\epsilon_N)$满足$Gauss-Markov$假设：

$$
 E(\epsilon) = \mathbf{0}\\
  Cov(\epsilon) = \sigma^2\mathbf{I}\\
  Cov(\epsilon, x) =\mathbf{0}
$$

 - 优化目标

$$
  RSS(\beta) = (y-X^T\beta)^T(y-X^T\beta)
$$



## 2 加权最小二乘法

- 加权最小二乘法和普通最小二乘法形式类似，只是残差不满足$Gauss-Markov$假设，其残差的协方差不要求是单位矩阵，而是对角阵，且对角线的值不一定相等。

$$
  E(\epsilon) = \mathbf{0}\\
  Cov(\epsilon) = \sigma^2\mathbf{D}\\
  Cov(\epsilon, x) =\mathbf{0}
$$

  	其中$\mathbf{D}$是对角阵而不是单位阵$\mathbf{I}$

 - 优化目标

$$
RSS(\beta) = (y-X^T\beta)^T\mathbf{W}(y-X^T\beta)
$$

​	其中$W$是对角阵

 - 求解

$$
dRss(\beta)
  \\ = d(y-X^T\beta)^TW(y-X^T\beta)+(y-X^T\beta)^TWd(y-X^T\beta)
  \\ = tr(d\beta^TXW(y-X^T\beta)) + tr((y-X^T\beta)^TWX^Td\beta)
  \\ = tr(2(XW(y-X^T\beta))^Td\beta)
  \\ \frac{\part Rss}{\part \beta} =2(XW(y-X^T\beta))=0
  \\ XWy=XWX^T\beta
  \\ \beta = (XWX^T)^{-1}XWy
$$
